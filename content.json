{"posts":[{"title":"Language Models, BERT to ChatGPT","text":"I am hearing ‘ChatGPT’ from everywhere. Probably, you do too. I hadn’t looked into it until recently; because I thought this was another language model trained with bunch of data. (Actually, I have hundreds of paper “to read” and I didn’t want to add another one to my pile.) So, eventually I played with it, and yes I was shocked by the quality of the generated responses. Here are some examples. You can even ask it to program~! And it will return a working code even with comments. (Well, now we have GPT-4 which you can use to code a website out of a mockup image of your website.) I believe now the academia (at least) is in real danger. It seems like for now we do not have a way to tell whether a writing is created by a human or generated by a pre-trained language model (PLM). I ran a plagiarism checker and saw if this code was a copy of any piece of code accessible on the Internet. I used Turnitin and the plagiarism score was only 9% (which is much less than a homework submission of an average college class). A possible source of the above code is Qiskit, which has a code base for open-source quantum development (Qiskit.optimization.applications.ising.knapsack), and I don’t think it’s likely that the code is a copy. Now, already there are a few scientific articles that added GPT as a co-author of the paper, which are accepted as legitimate papers. Again, GPT is another transformer-based language model; but, trained really well. However, there’s no way I can just close my eyes and treat it as another PLM. And, anyone who’s studying machine learning should understand how it become a thing. What is (Chat)GPT? According to Wikipedia, ChatGPT is… Generative Pretrained Transformer (GPT), Based on OpenAI’s GPT-3 family of Large Language Model (LLM), Fine-tuned using both supervised and reinforcement learning.Fine-tuned using both supervised and reinforcement learning. Alright, so let’s start with Transformer Attention Mechanism and TransformerIn order to understand Transformer, we need to go back all the way to Recurrent Neural Network (RNN) and Language Model (LM) Recurrent Neural NetworkRNN is a type of neural network designed for processing sequential data, such as temporal or linguistic data. Unlike feedforward networks, RNNs maintain a hidden state that passes the previous information over time steps. At each time step, the hidden state is updated based on the current input and the previous hidden state. This allows the model to capture temporal dependencies in the data. We can mathematically describe the forward pass of RNN as below: $$\\begin{align*}h_t &amp;= tanh(Wh_{t-1} + Ux_t + b) \\y_t &amp;= softmax(Vh_t + c)\\end{align*}$$ where: $x_t$ is the current input vector h_t is the hidden state vector U, W, and V are the learnable weight parameters for the input-to-hidden, hidden-to-hidden, hidden-to-output, respectively b and c are the bias vectors for hidden and output layers, respectively RNNs are a popular choice for the neural machine translation (NMT) models. The basic architecture of an NMT model consists of an encoder RNN and decoder RNN. The encoder RNN takes the input sentence in the source language and it generates a fixed-length vector representation (context vector) of the entire sentence at the end. The decoder RNN takes the context vector and generates the translation in the target language, token by token; this architecture is called Seq2Seq model, and the way it generates the target sequence is called autoregressive model. Issues with the RNN models Difficult to retain information from a distant word That is, hard to learn long-distance dependencies “Vanishing gradients” problem Derivative of the sigmoid is always below 0.25, hence multiplying too many derivatives according to the chain rule will end up near zero values. Difficult to parallelize operations Each operation depends on the previous operation. Uni-directional Either forward or backward Attention MechanismTo improve the performance of the NMT models, attention mechanisms can be added to the decoder RNN. Instead of relying only on the final context vector, we want to “attend” to any part of the input sequence. Attention allows to focus on different parts of the input sequence, based on the relevance of each input term to the current output term. The advantages of the attention mechanisms are: improves performance (in many applications) It’s very useful to allow decoder to focus on certain parts of the source Solves the bottleneck problem Attention allows decoder to look directly at source; bypass bottleneck Helps with vanishing gradient problem Provides shortcut to faraway states Provides some interpretability By inspecting attention distribution, we can see what the decoder was focusing on The barriers of attention mechanisms (and solutions) are The notion of order is gone. Solution: position embeddings The weighted sum does not provide non-linearity for deep learning. Solution: Add a feed-forward network with a non-linear function (e.g., ReLU) to each layer. We need to ensure that the model cannot obtain information from the future. Solution: Use a masking technique such that each time we change the set of keys and queries to include. TransformerTransformers are a type of NN architecture based on the attention mechanism that try to address some of the issues of RNN models. RNNs struggle with the long-term dependencies, as the memory can become diluted over time. Transformers use an attention mechanism to solve this issue. A typical transformer model looks like below: Transformers are based on the architecture that comprises the encoder and decoder part which is composed of multiple attention layers. This model also features techniques ,such as positional encoding, residual connections, layer normalization, to solve various problems. I will refer to this nice blog post written by Jay Alammar that explains the details of the Transformer architecture and how it works. Pre-trained Language ModelsBERTBERT (Bidirectional Encoder Representations from Transformers) is a transformer (encoder) model trained using a large amount of unannotated and unstructured text data from the Internet. BERT learns the relationships between words in a language and is trained on two specific tasks: Masked Language Modeling: Predicting a missing word (masked tokens) in a sentence. Next Sentence Prediction: Given two sentences A and B, predict if B comes after A. GPT-1GPT-1 (Generative Pre-Training) developed by OpenAI and released in 2018. OpenAI argued that there’s no need of a fine-tuning a pre-trained language model for specific natural (e.g., question-answering, document classification, etc.), and autoregressive decoder model is sufficient enough for most of the tasks. Please find the details from the paper, “Improving Language Understanding by Generative Pre-Training.” GPT-1 is an autoregressive Transformer decoder model, whereas BERT is a non-autoregressive Transformer encoder model. That is, an autoregressive model can only pay attention to the previous tokens, whereas a non-autoregressive model can pay attention to tokens before and after itself bidirectionally. GPT-2The following year, OpenAI released the second-generation of the GPT models. This is the first large language model (LLM) that has more than one billion model parameters (attributed to the collaboration of OpenAI and NVIDIA.) GPT-2 is trained using an extremely large dataset, which might contain “annotated” examples for specific language tasks (e.g., QA or translation). The extreme number of parameters and training examples enables the model to generate answers, rather to find answers. It started to use the prompt-tuning methods to guide the model in training for question answering, summarization, translation, and so on. You can find more details from the paper, “Language Models are Unsupervised Multitask Learns.” GPT-3The third-generation of the GPT models released in 2020, which is even larger in size (175 billion model parameters.) GPT-3 is trained to read and understand the context (paper, “Language Models are Few-Shot Learner“) and repeat generating answer in the same manner GPT-3 requires a demonstration by which it can understand the context and mimick the pattern it sees. This is the issues with all the GPT models. The models are not trained to follow human instructions. It needs to be provided with contextualized demonstration. Triggers are engineered in the pre-trained model, e.g., “Q:”, “A:” and “TLDR”. Questions without the context is difficult to be answered. InstructGPTInstructGPT (paper, Training Language Models to Follow Instructions with Human Feedback is developed to address these issues and released in 2022. The training method for the InstructGPT models differs from the previous ones. Demonstration data of desired output is created by human beings and collected for the supervised fine-tuned (SFT) model. GPT-3 generates outputs to a prompt, and a human labeler ranks the outputs. This comparison data is used to train a reward model (RM). With the reward model and a new prompt dataset, the policy model (PPO) is trained using reinforcement learning. ChatGPTChatGPT and InstructGPT are essentially the same model, except that for ChatGPT, different demonstration examples are used to train for better conversation between the users and the bot; E.g., Examples include dialogues created by human. This interactive information system can replace conventional search engines in many different ways.","link":"/2023/03/15/Language-Models-BERT-to-ChatGPT/"},{"title":"","text":"init","link":"/2023/03/16/index/"}],"tags":[{"name":"Generative AI","slug":"Generative-AI","link":"/tags/Generative-AI/"},{"name":"Machine Learning","slug":"Machine-Learning","link":"/tags/Machine-Learning/"},{"name":"Language Models","slug":"Language-Models","link":"/tags/Language-Models/"}],"categories":[{"name":"teaching","slug":"teaching","link":"/teaching/"}],"pages":[{"title":"Jiho Noh","text":"My name is Jiho, and I am an assistant professor of computer science at Kennesaw State University. My primary research interests are on the fields of NLP (natural language processing) and general AI (artificial intelligence) for intelligent search. Subtopics include: neural (graph) representation learning for knowledge discovery conversational technologies for information retrieval text processing including data mining, information extraction, entity recognition, and automatic knowledge database construction neural language understanding/generation If you are interested in this research field, please contact me via email.","link":"/about/index.html"}]}